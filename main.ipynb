{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "508ad8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.general import *\n",
    "\n",
    "import langchain as lc\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80331301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96mINFO\u001b[0m  Read URL as [https://sheep.ysh.xx.kg/]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "url = os.getenv('OLLAMA_SERVER_URL')\n",
    "\n",
    "info(f'Read URL as [{url}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e031cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model = 'gemma3:12b',\n",
    "    temperature = 2,\n",
    "    base_url = url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "caeea851",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'Simply reply all of the messages with \\'meow\\', adding by a number, and this number should increase by one each time user make inputs'),\n",
    "    ('user', '{input}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aa36afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1bd2d37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meow 1\n"
     ]
    }
   ],
   "source": [
    "print((prompt_template | model | parser).invoke({'input': 'Hello'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9641a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(x: str) -> str:\n",
    "    return ((prompt_template | model | parser).invoke({'input': 'Hello'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ec670d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = '''You're a extremely selfish player, which always maximum profits you could get.'''\n",
    "up = '''You're in a game, there's 100 dollars money in front you and a person you don't know.\n",
    "And now, the jury gives you the ability to decide how to split the money.\n",
    "Remember, the sum of the amount of money of you two people gain are always the same.\n",
    "By the way, each person would either get some money or even get no money.\n",
    "Now, you should reply with the amount of money you'd like to take, just reply with this number only without printing other any information.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d335135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', sp),\n",
    "    ('user', up)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ebd52145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print((template | model | parser).invoke({}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
